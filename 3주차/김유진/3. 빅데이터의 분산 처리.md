# 대규모 분산 처리의 프레임워크
## 구조화 데이터와 비구조화 데이터
- 구조화 데이터: 스키마가 명확하게 정의된 데이터
- 기존 데이터 웨어하우스에서는 데이터는 항상 구조화된 데이터로 축적하는 것이 일반적이었다.
- 비구조화 데이터: 스키마가 없는 데이터, 빅데이터
- 비구조화 데이터를 분산 시스템에서 처리하는 것이 데이터 레이크
- 스키마리스 데이터: 기본 서식은 있지만, 스키마가 정의 안됨

### 데이터 구조화의 파이프라인
- 데이터 소스에서 데이터 수집
- 분산 스토리지에 비구조화 데이터/스키마리스 데이터 보존
- 열 지향 스토리지로 구조화 데이터 변환
  - 시간에 따라 증가하는 데이터는 팩트 테이블
  - 부속 데이터를 디멘전 테이블로 취급
- 비구조화 데이터 > 열 지향 스토리지 변환 과정에서는 많은 컴퓨터 리소스가 소비되기 때문에 Hadoop과 Spark 등의 분산 처리 프레임워크를 사용한다.

## Hadoop
- Hadoop은 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체
- 대규모 분산시스템을 구축하기 위한 공통 플랫폼의 역할
- 데이터는 분산 파일 시스템인 HDFS에 저장 > 다수의 컴퓨터에 파일을 복사하여 중복성을 높인다.
- 계산 리소스는 리소스 매니저인 YARN에 의해 관리
- 호스트의 수에 따라 사용할 수 있는 리소스의 상한이 결정됨
- 리소스 관리자를 사용하면 애플리케이션마다 실행 우선순위를 결정할 수 있음
### MapReduce, Hive
- MapReduce는 YARN 상에서 동작하는 분산 애플리케이션, 자바 프로그램 실행으로 비구조화 데이터 가공에 적합
- Apache Hive는 쿼리 엔진이며 쿼리를 자동으로 MapReduce 프로그램으로 편환하는 소프트웨어로 개발(MapReduce에 의존)
- 모두 배치 처리에는 적합하나, 애드 혹 쿼리를 여러번 실행하는 데는 부적합
- Tez: Hive 가속화를 위해 개발, MapReduce 단점을 해소 > 고속화 실현
- Hive on Tez는 MapReduce, Tez 모두를 사용해도 동작하는 현재의 Hive를 뜻함
### Impala, Presto
- 대화형의 쿼리 실행만 전문으로 하는 쿼리 엔진
- 순간 최대 속도를 높이기 위해 사용할 수 있는 리소스를 최대한 활용하여 실행
- **무거운 배치 처리에는 Hive 이용, 구조화 데이터를 대화식으로 집계하고자 할 때에는 Impala, Presto 사용**

## Spark
- 대량의 메모리를 활용하여 고속화 실현
- 디스크에서 읽고 쓰지 않고 가능한 한 많은 데이터를 메모리상에 올린 상태로 두어 디스크에는 아무것도 기록하지 않는다
- MapReduce를 대체하는 존재


# 쿼리 엔진
## 데이터 마트 구축의 파이프라인
1. 분산 스토리지에 저장된 데이터 구조화, 열 지향 스토리지 형식으로 저장(Hive)
2. 완성한 구조화 데이터를 결합, 집계하고 비졍규화 테이블로 데이터 마트에 써서 내보냄(Presto)
- Hive에서 만든 각 테이블의 정보는 Hive 메타 스토어로 불리는 데이터베이스에 저장

## Hive에 의한 구조화 데이터 작성
- 데이터 구조화 이후 대화형 쿼리 엔진, 배치형 쿼리 엔진 선택이 중요
- Hive의 쿼리를 개선하는 예시
  - 서브 쿼리 안에서 레코드 수 줄이기
    - 읽어들이는 데이터 양을 의식하면서 쿼리 작성하는 것이 중요
    - 초기에 팩트 테이블을 작게 하는 것
    - 결합하기 전에 데이터의 양을 감소시키기
  - 데이터의 편향을 방지하는 방법
    - 데이터의 편차를 최대한 없애고 모든 노드에 데이터가 균등하게 분산되도록

## 대화형 쿼리 엔진 Presto의 구조
- 플러그인 가능한 스토리지: 하나의 쿼리 안에서 여러 데이터 소스에 연결 가능
- 원래 스토리지가 열 지향 데이터 구조로 되어 있어야 함
- ORC 형식의 로드에 최적화되어있다.
- 다양한 데이터 소스를 테이블로 참고할 수 있다.(MySQL, 분산 스토리지 상의 팩트 테이블)
- CPU 이용 효율이 높으므로(멀티스레드) 데이터 읽기 속도가 쿼리의 실행 속도를 결정한다.
- 중간에 끼어들 수 없기 때문에 너무 큰 쿼리를 실행해서는 안된다.
- 쿼리 실행 과정에서 디스크에 쓰기를 하지 않음, 모든 데이터 처리는 메모리에서 실시
- **디스크가 필요한 일부 데이터 처리는 Hive에 맡기고, 나머지는 Presto에서 실행**
- 기본적으로 분산 결합, 브로드캐스트 결합을 사용할 수도 있음

## 데이터 분석의 프레임워크 선택하기
- MPP 데이터베이스: 완성한 비정규화 테이블의 고속 집계
- Hive: 데이터양에 좌우되지 않는 쿼리 엔진
- Presto: 속도 중시, 대화식으로 특화된 퀴리 엔진
- Spark: 분산 시스템을 사용한 프로그래밍 환경

## 데이터 마트의 구축
### 팩트 테이블
- 추가: 새로 도착한 데이터만을 증분으로 추가, 효율적이지만 잠재적인 문제 있음
- 치환: 팩트 테이블 전체를 다시 만든다, 처리 시간 우려
- 데이터블 파티셔닝: '추가'의 잠재적인 문제를 줄이기 위해 테이블을 물리적인 파티션으로 나눈 것

### 집계 테이블
- 팩트 테이블을 어느 정도 모아서 집계한 것
- 일일 집계: 데이터를 1일 단위로 집계한 것
- 집계 테이블을 작게 하려면 모든 칼럼의 카디널리티를 줄여야 한다.

### 스냅샷 테이블
- 정기적으로 테이블을 통째로 저장하는 방법
- 시간이 지남에 따라 점점 커지므로 일종의 팩트 테이블로 간주
- 나중에 다시 만들 수 없으므로 영구적인 저장소(데이터 레이크, 데이터 웨어하우스)에 보관
  
### 이력 테이블
- 변경된 데이터만을 기록
- 데이터 양을 줄이는 데는 도움이 되지만, 완전한 마스터 테이블 복원은 어렵다.
