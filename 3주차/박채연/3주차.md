<img width="616" height="292" alt="스크린샷 2025-07-30 오후 6 05 11" src="https://github.com/user-attachments/assets/6b68d37a-9fcb-4399-8786-64f78ee5792f" />

### 1. **데이터 소스 단계**
- 사용자 행동 로그  
- 구매 기록등의 스키마가 없는 비정형 데이터

### 2. 분산 스토리지 ( 예 Hadoop HDFS, S3 )
- /logs/view_log/2025-07-30.log  
- /orders/2025-07-30.csv  
이런 식으로 구조화도 안되어 있고, 포맷도 전부 다르므로, 이를 가공해주어 열 지향 스토리지에 저장해야한다.

가공되지 않은 데이터 → 테이블 스키마로 처리해주는 도구 : spark 나 hive

### 3. 구조화 ( sql로 다룰 수 있다 )
- view_log 텍스트 → view_event 테이블  
- order.csv → order 테이블로 변환

### Hadoop - 대규모 데이터 세트를 분산된 환경에서 처리할 수 있는 도구  
<img width="635" height="253" alt="스크린샷 2025-07-30 오후 6 05 19" src="https://github.com/user-attachments/assets/fe4c783d-4954-4d42-b846-0d0d9d7bd342" />

- 특징  
수천대 서버로 확장 가능, replica 를 둬서 데이터 손실 최소화, 대규모 데이터 처리 가능, 오픈소스라 수정 가능  
- 한계  
배치 처리 방식이라 실시간 분석 어려움 -> spark 로 보완가능  
초기 설정 관리 복잡, 클러스터 유지에 많은 하드웨어 자원 필요

### 배치형 쿼리 엔진 hive, 대화형 쿼리 엔진인 presto
1. hive  
결과를 디스크에 파일로 저장  
2. presto  
원본 데이터를 두고, 스키마를 입혀 SQL로 조회 가능하게 함

### 분산 스토리지  
빅데이터는 대부분 다수의 컴퓨터를 사용하여 파일을 여러 디스크에 복사한 형태의 분산 스토리지를  사용한다.

- 여러 디스크에 복사된 데이터는 일부 하드웨어가 고장나더라도 손실되지 않는다.  
- 데이터 양이 늘어나도 데이터 읽기 쓰기를 다수의 하드웨어에 분산함으로써 성능이 떨어질 일이 없도록 고안되어있다.  
- 다만, 소량의 데이터를 다루기엔 오버헤드가 커서 적합하지 않다.  
- 예시 ) Hadoop - HDFS, 클라우스 서비스 - S3

### 벌크형 데이터 전송
<img width="629" height="310" alt="스크린샷 2025-07-30 오후 6 05 28" src="https://github.com/user-attachments/assets/26d96844-2f13-4cb0-9eb8-df7fd7af90f6" />

- 데이터 전송의 신뢰성이 중요한 경우 벌크형 도구를 사용해야한다.  
- 문제가 발생하여 여러번 데이터 전송을 재실행하고 싶은 경우 벌크형 도구를 사용해야한다.  
- 워크플로 관리 도구와의 조합이 좋다.

### 스트리밍형 데이터 전송
<img width="631" height="295" alt="스크린샷 2025-07-30 오후 6 05 33" src="https://github.com/user-attachments/assets/d366fe29-5260-4d97-9d69-dacf89840cf0" />

- 전송되는 데이터 양에 비해 실시간 통신을 위한 오버헤드가 커져 서버는 높은 성능이 요구된다.  
- 보낸 메시지는 hive 와 같은 쿼리 엔진이나, 메시지 큐나 메시지 브로커등의 중계 시스템에 전송되어 일정한 간격으로 함께 분산 스토리지에 저장된다.

### 메시지 브로커를 사용한 성능 개선  
메시지 배송에 의해 보내진 데이터를 분산 스토리지에 저장할때, 데이터 양이 많아짐에 따라 디스크의 성능이 한계에 도달하면 부하 제어가 어려워 문제가 생긴다.  
<img width="633" height="173" alt="스크린샷 2025-07-30 오후 6 05 39" src="https://github.com/user-attachments/assets/3617b0cd-ed35-4467-a8df-1ae73292a3f6" />


따라서, 스토리지에 바로 저장하는 방식이 아닌 데이터를 일시적으로 축적하는 메시지 브로커가 사용된다.  
<img width="633" height="276" alt="스크린샷 2025-07-30 오후 6 05 49" src="https://github.com/user-attachments/assets/43ed5ff2-8cc0-404d-8b1b-151acc19a6e5" />

예시 ) 오픈 소스 : 아파치 카프카, 클라우드 서비스 : 아마존 키네시스

consumer는 작은 단위의 메시지를 메시지 브로커(Kafka 등)로부터 일정한 간격으로 적당히 모아진 데이터를 분산 스토리지(S3, HDFS 등)에 기록한다.
<img width="613" height="267" alt="스크린샷 2025-07-30 오후 6 05 58" src="https://github.com/user-attachments/assets/cc0c294f-e4b7-4e96-a465-2b31235d71eb" />

메시지 브로커는 실시간 스트림 처리나 분산 스토리지 저장 등 다양한 목적의 Consumer들이 동일한 데이터를 독립적으로 처리할 수 있도록 Pub/Sub 기반 메시지 전달을 지원한다.

Consumer는 각자의 목적에 따라 일정 주기나 조건에 따라 pull을 통해 메시지를 가져와 처리할 수 있다.

### 메시지 배송에서의 신뢰성과 정합성 트레이드 오프

메시지 배송에선 효율을 중시하기에 트랜잭션을 처리하지 않은 경우가 많아 데이터의 중복이나 누락 가능성이 있다. 

1. at most once : 오류를 감지하면 재전송을하는 일반적 방식에선 보장 안되는 방법 
2. exatcly once : 양쪽의 통신 상태를 알기 위한 코디네이터의 존재가 필요하다. 하지만 시간이 너무 소요된다.
3. at least once : 일반적 배송 시스템에서 사용되는 방법으로 , producer→ broker → consumer 전송 후 consumer 가 broker에 ack를 보내는데 이 과정에서 장애가 발생하거나, producer→broker 전송시 장애가 나면 producer는 동일한 메시지를 다시 전송하는데 이때 메시지 중복이 발생할 수 있다.

### 중복제거는 어떻게?

TCP 와 다르게, 시퀀스 번호가 없어 메시지를 통해 보내는 데이터 특성에 따라 다양한 방식을 채택한다.

1. 벌크형 데이터 전송처럼 데이터 양이 고정된 경우
파일 안에 시작 위치 : 오프셋을 덧붙인다 → 같은 파일의 같은 장소 덮어쓰기 효과
2. 스트리밍 데이터 전송
모든 메시지에 uuid를 붙이기 → 다만, 과거에 전송된 uuid 를 모두 기억해야하는 비현실적 문제 최신의 것만 기억한다면 높은 신뢰도 달성

### 메시지 브로커 정리
<img width="622" height="337" alt="스크린샷 2025-07-30 오후 6 19 36" src="https://github.com/user-attachments/assets/6a665fb3-b93d-4edc-8911-d7966ca273ab" />

정리하자면, 데이터 소스에서 발생한 방대한 로그나 이벤트를 직접 분산 스토리지에 저장하게 된다면, 스토리지 성능을 계속 높이는 업 스케일링을 하지 않는 이상 부하 제어가 힘들어진다.
따라서 중간에 메시지 브로커를 둔다.
즉, 데이터 유입 속도가 적고, 부하가 일정하다면 메시지 브로커는 과잉 설계 일 수 있다. 

다만, 메시지 브로커는 at-least-once 전달 보장을 기본으로 하며, 중복 메시지 발생 가능성이 존재한다. 이로 인해 로그, 사용자 이벤트 등 정합성보다 수집 자체가 중요한 경우에는 중복 허용 처리 방식이 일반적이다.

아무래도 과금, 결제, 재고등 정합성이 중시되는 경우엔 스트리밍 형 메시지 배송을 피하는 것이 가장 좋고, 트랜잭션 처리를 지원하는 데이터베이스에 어플리케이션이 직접 기록해야한다.  → 의문 ??

### 데이터 수집 시점과 이벤트 발생 시점의 차이

클라이언트 상에서 메시지가 생성된 시간인 이벤트 시간과 서버가 처리하는 프로세스 시간의 차이 때문에 생기는 문제를 어떻게 해결 가능한가?

시계열 데이터를 활용하면 이벤트 시간 기준으로 정렬하고, 열 지향 포맷으로 저장하면 풀스캔을 방지하며 빠르게 원하는 데이터만 집계 가능하다.

log_20230101.csv 같은 파일 이름은 **파일 생성 시간 또는 수집 시간 (프로세스 시간)** 기준이다.
안에 들어있는 데이터는 과거 이벤트까지 섞여 있으므로, 풀스캔을 통해 특정 날짜를 뽑아야한다.

<img width="625" height="385" alt="스크린샷 2025-07-30 오후 6 20 08" src="https://github.com/user-attachments/assets/63a8e731-7cf6-4df3-934d-46e081ef32aa" />

따라서, csv 를 열 기반 포맷 이벤트 시간 기준으로 정렬하게 되면 pushdown 가능하다. 다만, 테이블 수가 늘어난다는 단점이 있다.

<img width="621" height="340" alt="스크린샷 2025-07-30 오후 6 20 32" src="https://github.com/user-attachments/assets/721a03c8-7d06-4cc0-8fec-92aad597e74b" />

열 지향 스토리지에서 etl 수행하여 집계 결과를 데이터 마트에 넣어두는 방법은 실시간성이 부족하지만 쿼리 속도가 빠르다.

