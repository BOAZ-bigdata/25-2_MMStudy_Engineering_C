# 3주차

### 5-1 워크플로 관리

- 워크플로 관리
    - 정해진 업무를 원활하게 진행하기 위한 구조
    - 정기적으로 태스크를 실행 + 비정상적인 상태를 감지하여 그것에 대한 해결을 도움

- 태스크
    - 데이터를 잇달아 이동하면서 실행되는 개별 처리

- 워크플로 관리 도구의 기능
    - 태스크를 정기적인 스케줄로 실행 → 그 결과 통지
    - 태스크 간 의존 관계 정함 → 정해진 순서대로 빠짐없이 실행
    - 태스크 실행 결과 보관 + 오류 발생 시 재실행

- 선언형 워크플로 도구
    - XML, YAML 등의 서식으로 워크플로 기술
    - 미리 제공된 기능만 이용 가능
    - 그 범위 안이라면 최소한의 기술로 태스크를 정의할 수 있음
- 스크립트형 워크플로 도구
    - 태스크의 정의를 프로그래밍 가능
    - 유연성이 높음

- 오류로부터 복구 방법
    - 수작업에 의한 복구 설계 → 실패한 태스크 모두 기록 → 나중에 재실행
    - 재시도: 단순한 재실행
    - 백필: 플로우 전체를 처음부터 다시 실행
    
- 오류 복구의 안전성 확보
    - 멱등한 조작: 원자성 조작 → 각 태스크가 시스템에 변경을 가하는 것을 한 번만 할 수 있게 설계
    - 동일한 태스크를 여러 번 실행해도 동일한 결과가 되도록 함
    - 현실에서는 항상 멱등한 태스크를 구현하기 어려움 → 테이블 파티셔닝
    - 워크플로 전체를 멱등화 하기 → 처음부터 재실행해도 안전
- 외부 시스템의 부하 컨트롤
    - 태스크 큐: 병렬화하여 태스크를 실행
    - 태스크 수의 적정화: 너무 크거나 너무 작지 않은 정도로 잘 분할하기
    
- 데이터 플로우
    - 다단계의 데이터를 처리하는 흐름

- MapReduce의 구조
    1. 파일을 일정 크기로 나누어 작은 데이터인 스플릿을 만듦
    2. 나눈 데이터를 읽어 들여 포함된 단어를 카운트
    3. 분할된 데이터를 처리: Map
    4. 그 결과를 모아서 집계: Reduce

- DAG
    - 방향성 비순환 그래프
    - 태스크의 의존 관계와 실행 순서를 정의해둠
    - Spark에서는 프로그래밍 언어를 사용해서 정의

- 데이터 플로우
    - 로드되는 데이터를 만드는 부분
    - 비구조화 데이터를 가공하여 CSV 파일 등을 만들어 분산 스토리지에 써넣음
    - 이후 태스크의 실행이나 SQL에 의한 쿼리의 실행은 워크플로에 맡김

- 스트림 처리
    - 분산 스토리지를 거치지 않고 처리를 계속하는 것
    - 과거의 데이터를 취급하는데는 부적합

- 배치 처리와 스트림 처리
    - 둘은 서로의 결점을 보완하는 관계
    - 따라서 둘을 적절히 통합하는 것이 적절
    
- 람다 아키텍처
    - 배치 레이어: 대규모 배치처리
    - 스피드 레이어: 스트림 처리
    - 장점: 실시간 뷰의 결과는 나중에 배치 뷰로 치환 → 스트림처리의 결과는 일시적으로 사용, 이후 배치 처리에 의해 올바른 결과 로드 가능

- 카파 아키텍쳐
    - 배치 레이어나 서빙 레이어를 완전히 제거하고 스피드 레이어만 남김
    - 단점: 부하가 높아짐

### 6장 빅데이터 분석 기반의 구축

- 스키마리스 데이터 수집
    - API 수집 → MongoDB → Jupyter Notebook

- Spark에 의한 분산 환경
    - 스크립트 언어에 의한 프로그래밍 가능
    - 대규모 분산 처리를 이용해 대량의 데이터 처리 가능

- Hadoop에 의한 데이터 파이프라인
    1. 일일 배치 처리를 태스크화
    2. Embulk에 의한 데이터 추출
    3. Hive에 의한 데이터 구조화
    4. Presto에 의한 데이터 집계

- Airflow
    - 스크립트 형에 의한 워크플로 관리
    - 여러 태스크로 이루어진 DAG 형태로 정의
    - → 태스크 간 의존 관계를 정의해두면, 실행 순서는 자동으로 결정
    - Operator: Airflow에서 태스크를 만들기 위한 클래스

- 클라우드 서비스에 의한 데이터 파이프라인
    - AWS
    - 구글 클라우드 플랫폼
    - 트레주어 데이터