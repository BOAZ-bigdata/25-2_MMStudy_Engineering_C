분산 시스템에 의한 데이터 처리 고속화 

빅데이터의 취급이 어려운 이유는 크게 두 가지다. 

 

1. 데이터의 분석 방법을 모름  

2. 데이터 처리의 비용 

이 두 가지를 동시에 갖춰야 가치 있는 정보를 얻을 수 있다. 

 

그 중 데엔 에게 중요한 것 : 데이터 처리의 비용 ( 어떻게 효율적으로 처리할 것인가? )

 
빅 데이터 기술의 예시 
Hadoop ( 대용량 데이터 분산 처리 프레임 워크) p3~p10
구글의 분산 처리 프레임워크 MapReduce 를 참고하였음 -> SQL과 같은 쿼리 언어로 실행하기 위해 Hive 가 개발되어 같이 쓰임 

 

* 인덱싱 처리 

하둡의 핵심 구성 요소인 HDFS(Hadoop Distributed File System)는 기본적으로 전통적인 관계형 데이터베이스처럼 복잡한 인덱스를 제공하지 않습니다. 데이터가 대규모 파일 형태로 분산 저장되기 때문입니다. 하지만 하둡 생태계에는 이러한 한계를 극복하고 효율적인 데이터 접근을 가능하게 하는 다양한 방법들이 있습니다.

하이브(Hive): 하이브는 HDFS 위에 구축된 데이터 웨어하우스 시스템으로, SQL과 유사한 HQL(Hive Query Language)을 사용하여 데이터를 쿼리할 수 있습니다. 하이브는 내부적으로 데이터를 테이블처럼 관리하며, 특정 칼럼에 대한 **인덱스(Index)**를 생성할 수 있습니다. 이는 전통적인 RDBMS의 인덱스와 유사하게 특정 조건에 맞는 데이터를 더 빠르게 찾을 수 있도록 돕습니다. 하지만 대규모 데이터셋에서는 인덱스 관리 오버헤드가 클 수 있어, 주로 정적으로 자주 접근되는 소규모 테이블이나 특정 필터링 조건에 사용됩니다.
* 데이터 연결

하이브 (Hive) 조인: 하이브는 내부적으로 맵리듀스 엔진을 사용하여 조인을 처리합니다. 사용자에게는 SQL과 유사한 구문으로 조인 기능을 제공하므로, 관계형 데이터베이스와 유사하게 JOIN 키워드를 사용하여 테이블을 연결할 수 있습니다. 하이브는 조인 최적화를 위해 맵-측 조인을 자동으로 선택하거나, 버케팅된 테이블 간의 조인 성능을 향상시키는 등 다양한 기능을 제공합니다.
스파크 (Spark) 조인: 스파크는 맵리듀스보다 훨씬 효율적인 조인 기능을 제공합니다.
셔플 해시 조인 (Shuffle Hash Join): 맵리듀스의 리듀스-측 조인과 유사하지만, 스파크의 최적화된 셔플 메커니즘 덕분에 더 빠릅니다.
브로드캐스트 해시 조인 (Broadcast Hash Join): 스파크의 대표적인 고성능 조인 방식입니다. 작은 데이터프레임을 클러스터의 모든 워커 노드에 브로드캐스트하여 메모리에 로드한 후, 큰 데이터프레임과 조인합니다. 맵-측 조인과 유사하며, 매우 빠릅니다.
정렬 병합 조인 (Sort Merge Join): 조인할 두 데이터프레임을 조인 키를 기준으로 정렬한 후, 병합하는 방식입니다. 데이터가 이미 정렬되어 있거나, 브로드캐스트하기에는 너무 큰 경우에 사용됩니다.
버케팅 조인 (Bucket Join): 두 테이블이 동일한 버케팅 키와 버킷 수를 가지고 있다면, 스파크는 해당 버킷에 속하는 데이터만 조인하여 매우 효율적인 조인 성능을 제공합니다.
HBase 조인: HBase는 기본적으로 조인 기능을 제공하지 않습니다. HBase의 특성상 조인이 필요한 복잡한 쿼리보다는 키 기반의 빠른 접근에 중점을 둡니다. 만약 HBase 데이터 간의 조인이 필요하다면, 스파크와 같은 외부 처리 엔진을 사용하여 HBase의 데이터를 로드한 후 조인 작업을 수행해야 합니다.
 

NoSQL 빈번한 데이터의 빠른 읽기/쓰기 및 분산 처리 
1, Key - Value Store 

2. Document Store

3. Wide-Column Store 



* 읽기/쓰기 및 분산 처리가 빠른 이유 

대부분 스키마가 없거나(Schema-less) 매우 유연한 스키마(Flexible Schema)를 가집니다. 데이터를 저장할 때 미리 구조를 정의할 필요가 없으며, 각 데이터는 고유한 구조를 가질 수 있습니다. 이는 다음과 같은 이점을 제공합니다.

빠른 데이터 삽입: 데이터를 저장하기 전에 복잡한 스키마 유효성 검사나 관계 검사를 할 필요가 없어 삽입 속도가 빠릅니다.
단일 데이터 단위 접근: 대부분의 NoSQL 데이터 모델(키-값, 문서, 와이드 컬럼)은 애플리케이션이 필요로 하는 데이터를 단일 단위(예: 문서)로 저장하여, 데이터를 읽어올 때 복잡한 조인 연산 없이 한 번의 요청으로 필요한 모든 데이터를 가져올 수 있습니다. 이는 I/O 및 CPU 부하를 줄여줍니다.
해싱(Hashing) 또는 트리(Tree) 기반 인덱싱:

대부분의 키-값 스토어는 내부적으로 **해시 테이블(Hash Table)**이나 **B-트리(B-Tree) 또는 B+트리(B+Tree)**와 같은 자료구조를 사용하여 키와 값의 위치를 매핑합니다.
해싱: 키를 해시 함수에 넣어 데이터가 저장된 물리적 위치(주소)를 계산합니다. 이 계산된 주소를 통해 데이터에 직접 접근하므로, 키만 알면 매우 빠르게 데이터를 찾을 수 있습니다. 이상적인 해시 테이블에서 검색 시간 복잡도는 O(1) (상수 시간)에 가깝습니다.
트리 구조: B-트리나 B+트리는 데이터를 정렬된 상태로 저장하고, 트리 구조를 따라 탐색하여 원하는 키를 찾습니다. 이는 해싱만큼은 아니지만, 데이터가 많아져도 로그 시간 복잡도(O(logN))로 효율적인 검색이 가능합니다. 범위 검색(예: 특정 키부터 다른 키까지의 모든 데이터)에도 유리합니다.
*  NoSQL 의 수평적 확장성 

대부분 처음부터 분산 시스템으로 설계되어 수평적 확장이 용이합니다. 데이터를 여러 서버에 분산하여 저장하고 처리할 수 있으므로, 데이터 양이나 트래픽이 증가해도 서버를 추가하는 것만으로 성능을 선형적으로 확장할 수 있습니다. 이는 대규모 데이터와 높은 동시 접속 처리에 매우 유리하며, 분산 환경에서의 읽기/쓰기 작업 처리량(throughput)을 크게 향상시킵니다.

 

수평적 확장(Horizontal Scaling)은 시스템의 용량이나 처리량을 늘리기 위해 기존 서버의 성능을 업그레이드하는 대신, 새로운 서버(노드)를 추가하여 전체 시스템의 능력을 확장하는 방식을 의미합니다. 이는 특히 웹 서비스, 빅데이터 처리, 분산 데이터베이스 등 대규모 트래픽과 데이터를 다루는 시스템에서 널리 사용됩니다.

수평적 확장은 단순히 서버 대수를 늘리는 것을 넘어, 각 컴포넌트가 어떻게 분산되고 협력하는지에 대한 복잡한 설계와 기술이 필요합니다. 주요 방법과 관련 기술들은 다음과 같습니다.

 

1. 로드 밸런싱 (Load Balancing)

개념: 여러 서버에 들어오는 네트워크 트래픽(요청)을 균등하게 분산시켜주는 기술입니다. 단일 서버에 트래픽이 집중되는 것을 막고, 각 서버의 부하를 줄여 시스템의 안정성과 응답 속도를 향상시킵니다.
작동 방식:
사용자의 요청은 먼저 로드 밸런서(하드웨어 또는 소프트웨어)에 도달합니다.
로드 밸런서는 미리 설정된 알고리즘(예: 라운드 로빈, 최소 연결, IP 해시 등)에 따라 요청을 백엔드 서버 중 하나로 전달합니다.
이때, 로드 밸런서는 각 서버의 상태(Health Check)를 지속적으로 모니터링하여, 장애가 발생한 서버로는 요청을 보내지 않아 서비스 중단을 방지합니다.
예시: 웹 서버를 여러 대 두었을 때, 사용자 요청을 이 웹 서버들에게 고르게 분배하여 각각의 서버가 과부하되지 않도록 합니다.

2. 데이터베이스 샤딩 (Database Sharding) 또는 파티셔닝 (Partitioning)

개념: 단일 데이터베이스가 처리하기 어려운 대량의 데이터를 여러 개의 작은 단위(샤드 또는 파티션)로 분할하여 서로 다른 데이터베이스 서버에 분산 저장하는 기술입니다.
작동 방식:
샤드 키(Shard Key) 정의: 데이터를 분할할 기준이 되는 키를 정의합니다. 예를 들어, 사용자 ID의 범위, 지리적 위치, 특정 해시 값 등이 될 수 있습니다.
데이터 분배: 샤드 키에 따라 데이터가 특정 샤드(서버)에 할당됩니다.
쿼리 라우팅: 애플리케이션은 어떤 데이터가 어느 샤드에 있는지 알고 있거나, 별도의 라우팅 계층을 통해 쿼리를 올바른 샤드로 전달합니다.
장점:
읽기/쓰기 성능 향상: 각 샤드가 전체 데이터의 일부만 처리하므로, 쿼리 응답 시간이 단축되고 처리량(throughput)이 증가합니다.
가용성 및 내결함성: 한 샤드에 문제가 발생해도 다른 샤드는 독립적으로 작동하므로 전체 시스템 장애로 이어질 가능성이 줄어듭니다.
확장성: 데이터 증가에 따라 새로운 샤드를 추가하여 용량을 쉽게 확장할 수 있습니다
 
데이터 파이프라인  p11~
: 데이터 수집- 추출 - 변환 - 처리 - 저장 - 워크플로 관리까지 여러 단계를 거쳐 전달해가는 데이터로 구성되는 시스템을 데이터 파이프라인이라고 한다. 


1. 데이터 수집 
데이터 전송의 방법은 크게 두 가지가 있다. 

1. Bulk 형 
Bulk 형은 이미 존재하는 데이터를 정리해 추출하는 방법으로 정기적을 데이터를 수집하는데에 사용한다

2. Streaming 형 
Streaming 형은 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법으로 데이터를 수집하는데 사용된다.

 

기존의 경우, 데이터 웨어하우스에서 다루는 데이터는 주로 벌크 형 방법이 이용되었으나, 빅데이터의 세계에서 모바일 애플리케이션등이 증가함에 따라 오히려 스트리밍 형 방법이 주류가 되고 있고, 스트리밍 형 방법으로 받은 데이터는 아무래도 실시간으로 처리된다. 이것을 스트림 처리(Stream Processing) 이라고 한다

 

반대로 장기적인 데이터 분석을 위해서는 대량의 데이터를 저장하고 처리하는데 적합한 시스템은 배치 처리(Batch Processing) 구조이다

 

2. 데이터 저장 p14~19

1. 데이터 레이크 (Data Lake)
정의: 데이터 레이크는 정형, 반정형, 비정형 데이터를 원시(raw) 형태 그대로 대규모로 저장하는 중앙 집중식 저장소입니다. 마치 모든 종류의 물을 담을 수 있는 거대한 '호수'와 같다고 생각할 수 있습니다. 이 곳에 존재하는 데이터를 로우 데이터 ('raw data')라고 하기도 한다. 이 곳으로 부터 데이터 웨어하우스에 저장하기까지의 흐림이 ETL 프로세스다.


2. 데이터 웨어하우스
정의 : 데이터 웨어하우스(Data Warehouse, DWH)는 기업의 다양한 운영 시스템에서 발생하는 데이터를 추출, 변환, 적재(ETL: Extract, Transform, Load)하여 
분석 및 의사 결정을 지원하기 위해 구축된 중앙 집중식 데이터 저장소입니다. 특정 비즈니스 주제에 맞춰 데이터를 통합하고,  대량의 이력 데이터를 장기간 보관하여 과거 추세 분석이나 미래 예측에 활용될 수 있도록 설계됩니다. 데이터 웨어하우스에 필요한 데이터만을 추출하여 데이터 마트를 구축하고 BI 도구 와 조합시켜 데이터를 시각화하는데 사용한다. 


3. 데이터 마트 (Data Mart)
정의: 데이터 마트는 특정 부서나 특정 비즈니스 주제(예: 마케팅, 영업, 재무)에 초점을 맞춰 데이터 웨어하우스로부터 추출, 가공된 데이터를 담고 있는 소규모 데이터베이스입니다. 데이터 웨어하우스의 하위 집합이라고 볼 수 있습니다. 

* 4. 데이터 레이크하우스 (Data Lakehouse)
정의: 데이터 레이크하우스는 데이터 레이크의 유연성과 데이터 웨어하우스의 체계적인 관리 및 성능 이점을 결합한 새로운 데이터 아키텍처입니다. 데이터 레이크 위에 데이터 웨어하우스의 기능을 더하여, 모든 종류의 데이터를 저장하면서도 고성능 분석과 ACID 트랜잭션(원자성, 일관성, 고립성, 지속성)을 지원합니다.

 

* 데이터 사일로 ( Data Silo )
데이터 사일로(Data Silo)는 기업이나 조직 내에서 데이터가 부서, 팀, 시스템별로 분리되어 저장되고 관리되어 서로 공유되거나 통합되지 못하는 상태를 의미합니다. 마치 농장의 곡식 저장고인 '사일로(Silo)'처럼 데이터가 각자의 공간에 갇혀 외부와 단절된 형태를 띠는 것에 비유할 수 있습니다.

 

ETL 프로세스는 이러한 데이터 사일로를 해소하는 데 다음과 같은 역할을 합니다.

추출(Extract): 분리되어 있는 다양한 소스 시스템(예: 각 부서의 데이터베이스, 레거시 시스템, 클라우드 애플리케이션 등)에서 필요한 데이터를 추출합니다. 이는 데이터 사일로를 구성하는 각 "사일로"에서 정보를 꺼내는 과정입니다.
변환(Transform): 추출된 데이터를 분석 및 활용하기에 적합한 형태로 변환합니다. 이 과정에서 데이터 정제, 표준화, 중복 제거, 통합, 형식 변경 등이 이루어집니다. 각 사일로에서 다른 형태로 존재하던 데이터를 일관된 형식으로 만들어주는 핵심 단계입니다.
적재(Load): 변환된 데이터를 데이터 웨어하우스(Data Warehouse)나 데이터 레이크(Data Lake)와 같은 중앙 집중식 저장소에 적재합니다. 이렇게 하면 모든 부서의 데이터가 한곳에 모여 쉽게 접근하고 분석할 수 있게 됩니다.