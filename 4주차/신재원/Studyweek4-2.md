태스크 큐 

자원 소비량 Control 

워크플로 관리 도구에서 요구되는 역할은 외부 시스템의 부하 컨트롤이다 

태스크의 크기와 동시 실행 수의 조정을 해야 모든 태스크가 원활하게 실행된다 

처음으로 고려할 것 : 병렬화 

모든 트스크를 큐에 저장하고 일정 수의 워커 프로세스가 순서대로 꺼내면서 병렬화 

실제로 8코어의 서버에 8개의 워커로는 부족함

각 태스크는 CPU 를 사용뿐 아니라 디스크 IO 나 네트워크 IO도 소비함 - 8코어 20태스크 정도면 문제없다 


배치 형 데이터 플로우 

분산 스토리지로의 데이터 전송이 끝나면 분산 시스템의 프레임 워크를 사용가능 

SQL 뿐만 아니라 프로그래밍 언어 사용 가능 

MapReduce -> DAG (Directed acyclic graph)  방향성 비순환 그래프 로 대체 

Hadoop on Tez , Spark , Google Millwheel 로 대체 중 


Spark 의 DAG

DAG에 의한 프로그래밍의 특징이 '지연 평가' 이다 .

프로그램의 각 행은 실제로는 DAG의 데이터 구조를 조립하고 있을뿐 특별히 뭔가를 처리하지는 않음. 

데이터 플로우에서 프로그래밍할 수 있게 되면 데이터의 입출력을 모두 하나의 DAG로 기술할 수 있다.

데이터플로우 와 워크플로는 보완 관계이며 잘 나누어서 사용 


데이터를 읽어들이는 플로우

1. 데이터 소스에 액세스하면 성능 문제를 일으키기 쉽다

2. 분산 스토리지에 데이터를 복사함으로써 안정적으로 사용 

3. 분산 스토리지에서 데이터 플로우로서 실행 가능 이 모든 과정이 워크플로


데이터를 써서 내보내는 플로우 

데이터의 집계 결과를 외부 시스템에 써서 내보내는 경우에는 완전히 반대의 관계가 성립한다. 

1. 데이터 플로우 안에서 대량의 데이터를 외부에 전송은 피해야 한다.

2. 데이터 플로우의 출력은 일단 취급하기 쉬운 형식으로 변환(CSV 등) 후 분산 스토리지에 저장 

3. 이 데이터를 외부에 전송하는 것은 워크플로의 역할 


SQL 을 MPP 데이터베이스에서 실행하는 경우 = 데이터 웨어하우스의 파이프라인



분산 시스템 상의 쿼리 엔진에서 실행하는 경우 = 데이터 마트의 파이프라인

구조화 데이터를 만드는 부분까지 데이터 플로우 


스트리밍 형 데이터 플로우 

배치처리의 단점 : 시간이 걸린다 

실시간에 가까운 데이터 처리는 모두 생략 후 별개의 계통의 파이프라인 

시스템 모니터링 로그관리 시스템 복합 이벤트 처리 등이 실시간성이 높다. 

가장 큰 차이점 : 분산 스토리지에 보관 유무 , 데이터의 양의 제한(유한 데이터, 무한 데이터)
 
배치 처리와 스트림 처리는 서로 결점을 보완하는 관계로 사용 가능 


스트림 처리의 결과를 배치로 치환하기 

스트림 처리의 두 가지 문제 

1. 틀린 결과를 어떻게 수정할 것인지

2. 늦게 전송된 데이터의 취급 

이런 문제들의 전통적 대처 방법은 스트림 처리와 별개로 배치 처리를 실행하는 것 


람다 아키텍쳐 

모든 데이터를 배치 레이어에서 처리. 장기적인 스토리지에 저장

배치 처리 결과는 서빙 레이어를 통해서 접근 이 결과가 배치 뷰 

또 다른 경로로 스피트 레이어를 통해서 접근 이 결과가 리얼타임 뷰

이것은 배치 뷰가 업데이트 될 동안만 이용하고 오래된 데이터는 순서대로 삭제 

카파 아키텍쳐

람다 아키텍쳐의 문제점 : 나쁜 개발 효율 (모두 같은 처리를 하고 있으므로)

이를 단순화한 것이 카파 아키텍쳐

스피드 레이어만을 남기고  대신 메세지 브로커의 데이터 보관 기간을 충분히 길게 한다.

카파 아키텍쳐의 문제점 : 부하가 높아진다


아웃 오브 오더 

기술적으로 프로세스 시간 과 이벤트 시간의 차이 

스트림 처리에서는 종종 시간 일정 간격으로 윈도우를 만들고 그 안에서 데이터 집계를 한다 






