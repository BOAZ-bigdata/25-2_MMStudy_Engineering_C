# 워크플로 관리
## 워크플로 관리
- 기업 내의 정형적인 업무 프로세스와 같이 정해진 업무를 원활하게 진행하기 위한 구조
-  워크플로 관리 도구는 태스크 실행에 실패할 수 있기 때문에 사용
-  선언 형(XML,YAML)
  - 미리 제공된 기능만 이용
  - 유지 보수성이 높음
- 스크립트 형
  - 유연성이 장점
## 오류로부터의 복구 방법 먼저 생각하기
- 동일 플로우에 동일 파라미터를 건네면, 완전히 동일한 태스크가 실행되도록 하는 것
- 실패한 플로우를 선택하여 재실행하면 복구가 완료됨(과거 플로우,파라미터 DB에 기록)
- 여러 번 발생하는 오류는 자동적인 재시도를 통해 복구
- 재시도 횟수 주의하기: 너무 많거나 적으면 안됨
- 이상적으로는 재시도 없이 오류를 통지하는 것이 좋다.
- 백필(backfill): 파라미터에 포함된 일시를 순서대로 바꿔가면서 일정 기간의 플로우를 연속해서 실행하는 구조
## 멱등한 조작으로 태스크를 기술하기
- 원자성 조작: 각 태스크가 시스템에 변경을 가하는 것을 한 번으로 제한
- 멱등한 조작: 동일한 태스크를 여러 번 실행해도 동일한 결과가 되도록 하는 것
- 추가는 데이터가 중복되지만, 치환은 반복해도 결과가 변하지 않으므로 멱등하다
- 멱등한 추가
  - 현실에서 항상 치환을 사용할 수 없다(부하가 큼)
  - 테이플 파티셔닝 사고방식은 테이블을 1일 또는 1시간마다 파티션으로 분할하고 파티션 단위로 치환
- 원자성을 지닌 추가
  - 하나의 테이블에 데이터를 여러 번 추가하는 경우, 중간 테이블을 만들어 처리한 후 마지막에 목적 테이블에 한 번에 추가
## 워크플로 전체를 멱등으로 하기
- 데이터 수집 파이프라인: 테이블 파티셔닝 도입
- 벌크 형 데이터 전송: 날짜와 시간을 파라미터로 전달
- 데이터 마트 구축: 테이블마다 치환
- 추가는 재시도 시 중복의 가능성 때문에 문제시된다.
- 한 번 성공한 태스크를 취소 후 다시 재실행할 때는 명등한 태스크만이 안전하게 재실행가능
## 태스크 큐
- 모든 태스크는 일단 큐에 저장, 일정 수의 워커 프로세스가 그것을 순서대로 꺼내면서 병렬화 실현
- 서버 내부 요인의 문제인 경우에는 개선 가능
- <img width="680" height="265" alt="image" src="https://github.com/user-attachments/assets/e9a0f03e-a365-4800-8c83-046b320214c9" />
- 작은 태스크를 다수 실행하면 오버헤드가 커짐 > 수백 개의 파일을 하나의 태스크로 하는 것이 적정 크기


# 배치 형의 데이터 플로우
## MapReduce의 시대는 끝났다
- 파일을 일정 크기로 나누어 스플릿을 만든다
- 나눈 데이터를 읽어들여 그중에 포한된 단어를 카운트(Map)
- 단어별로 그 수의 합계를 구한다(Reduce)
- Map, Reduce 하나의 사이클이 끝나지 않으면 다음 처리로 이동하지 않으므로 지연이 적은 집계를 실현하기 어렵다
## MapReduce를 대신할 새로운 프레임워크
- DAG(directed acyclic graph; 방향성 비순환 그래프)
- 데이터 플로우에서는 DAG를 구성하는 각 노드가 모두 동시 병행으로 실행
- 데이터 파이프라인 전체를 DAG로 조립하고 나서 실행에 옮김으로서 내부 스케줄러가 분산 시스템에 효과적인 실행 계획을 세워준다.
## 데이터 플로우와 워크플로를 조합하기
- 데이터 플로우로부터 읽어들일 데이터는 분산 스토리지에 배치
- 플로우 완성될 때까지의 개발 중에는 분산 스토리지에 복사된 데이터만을 이용
- 데이터를 읽어들일 때는 벌크형 전송 도구로 태스크 구현
- 데이터 플로우 안에서 대량의 데이터를 외부에 전송하는 것은 피하는 것이 무난
- 데이터 플로우 출력은 취급하기 쉬운 형식으로 변환, 분산 스토리지에 써넣는다(워크플로의 역할)
## 데이터 플로우와 SQL을 나누어 사용하기
- MPP 데이터베이스에서 실행하는 경우
  - <img width="556" height="228" alt="image" src="https://github.com/user-attachments/assets/1d67502c-b0df-4b19-a2ee-ce4deca31023" />
  - 로드되는 데이터를 만들고 분산 스토리지에 써넣는 부분까지 데이터 플로우의 역할
- 분산 시스템상의 쿼리 엔진에서 실행하는 경우
  - <img width="559" height="238" alt="image" src="https://github.com/user-attachments/assets/179681dc-d697-4110-8308-fef5406466ea" />
  - 구조화 데이터를 만드는 부분까지가 데이터 플로우의 역할
 

# 스트리밍 형의 데이터 플로우
## 배치 처리와 스트림 처리로 경로 나누기
- 분산 스토리지를 거치지 않고 처리를 계속하는 것이 스트림 처리
- 배치 처리는 1년 이상의 데이터 분석을 예상할 때
- 스트림 처리는 즉시 분석할 필요가 있을 때
## 배치 처리와 스트림 처리 통합하기
- 배치 처리에서는 데이터를 작게 나눠서 DAG에 흘려 넣는다, 스트림 처리에서는 끊임없이 데이터가 생성되고 그것이 DAG 안에 흘러들어감
- 유한 데이터: 실행 시에 데이터양이 정해지는 것, 배치 처리
- 무한 데이터: 제한 없이 데이터가 보내지는 것, 스트림 처리
- DAG를 사용한 데이터 플로우에서는 배치 처리와 스트림 처리를 동일하게 프로그래밍 하는 것이 가능
## 스트림 처리의 결과를 배치 처리로 치환하기
- 틀린 결과를 어떻게 수정할 것인가?, 늦게 전송된 데이터 취급 => 배치 처리를 별개로 실행시켜 후자의 결과가 옳다고 하는 것
- 람다 아키텍처
  - 배치 레이어에서 데이터 처리
  - 서빙 레이어에서 배치 처리 결과 접근(배치 뷰)
  - 다른 경로로 스트림 처리를 하기 위해 스피드 레이어 설치(실시간 뷰)
  - 스피드 레이어와 배치 레이어가 같은 처리를 구현하고 있으므로 번거롭다
- 카파 아키텍처
  - 스피드 레이어만을 남긴다
  - 메시지 브로커의 데이터 보관 기간을 길게 하여 문제가 생겼을 때 메시지 배송 시간을 과거로 설정
  - 부하가 높아진다
## 아웃 오브 오더의 데이터 처리
- 데이터는 이벤트 시간으로 집계해야 올바른 결과를 얻을 수 있다
- 이벤트 시간 윈도윙: 이벤트 시간에 의해 윈도우를 나누는 것
